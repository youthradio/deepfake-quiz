__NUXT_JSONP__("/", (function(a,b,c,d,e,f){b[0]={option:{id:"dcda55ac-2857-4269-8ac5-17e97c027680",title:c,a:{content:"‚ú® REAL ‚ú®",id:"c49f9c1c-781e-4c26-8b3f-e6685c1a4b7b"},b:{content:"‚ÄºÔ∏è FAKE ‚ÄºÔ∏è",id:"ba6baff3-d450-48b3-9d52-7c919ea6033c"},slug:c},image:"gifs\u002Fg2",prompt:{text:"\u003Cp\u003EYour friends send you a text message of a video with a politician talking about an inflammatory topic, but the video seems kind of strange. First off, the title seems like it‚Äôs trying to make you angry. Also, in the video, the politician isn‚Äôt blinking and seems to be stuttering a little. That‚Äôs not normal, is it? But the voice sounds real enough, and this definitely isn‚Äôt an impostor ... so you can‚Äôt quite decide. Is this video real and can you trust the information you‚Äôre getting from it?\u003C\u002Fp\u003E"},response:{text:"\u003Cp\u003EIn some cases, the mere suspicion that a strange video is a deepfake can be enough to cause turmoil. \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.washingtonpost.com\u002Fpolitics\u002F2020\u002F02\u002F13\u002Fhow-sick-president-suspect-video-helped-sparked-an-attempted-coup-gabon\u002F\" rel=\"nofollow\" target=\"_blank\"\u003EThis happened in the country of Gabon\u003C\u002Fa\u003E. When their president fell ill in Saudi Arabia, vague and conflicting government reports about his health led to people spreading conspiracy theories that he was dead and had been replaced by a body double. Eventually, these theories had become so prevalent that when the president finally gave a public speech, many assumed the footage of the speech was a deepfake. Eventually there was even a coup attempt from opposition parties ‚Äî even though, according to deepfake experts, the video appeared to be completely real!\u003C\u002Fp\u003E"}};b[1]={option:{id:"0cc7baa0-6d89-46cc-b454-0dfe18ccf2d6",title:d,a:{content:"TOTALLY NORMAL! üòä",id:"c1055239-6faa-4ac0-a9bc-93d94193fc99"},b:{content:"PROBABLY A SCAM ü§î",id:"6ed3a2d3-6578-48f0-8d8e-3d11ab3b1aa3"},slug:d},image:"gifs\u002Fg3",prompt:{text:"\u003Cp\u003EYou get a phone call from one of your coworkers at a really late hour. You don‚Äôt recognize the number they're calling from (maybe they got a new phone?), but you recognize their voice immediately even though it‚Äôs kind of mangled. They‚Äôre calling to tell you that the company needs you to put $1000 into this coworker‚Äôs bank account for ‚Äúbusiness purposes.‚Äù When you ask for details, they don‚Äôt say anything more, instead asking again for the $1000. Will you put the money in the bank account?\u003C\u002Fp\u003E"},response:{text:"\u003Cp\u003EThis actually happened to an anonymous employee at an unidentified tech firm earlier this year. This \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.theverge.com\u002F2020\u002F7\u002F27\u002F21339898\u002Fdeepfake-audio-voice-clone-scam-attempt-nisos\" rel=\"nofollow\" target=\"_blank\"\u003Eemployee received a phone call from a hacker and scammer\u003C\u002Fa\u003E using an audio deepfake to impersonate the company‚Äôs CEO. The voicemail left on the employee‚Äôs phone was asking for ‚Äúimmediate assistance to finalize an urgent business deal‚Äù in a human-like voice that sounded only vaguely like the CEO. Luckily, the anonymous employee immediately found it suspicious and didn‚Äôt give the scammers what they wanted. Though this anonymous employee caught on rather quickly, \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.theverge.com\u002F2019\u002F9\u002F5\u002F20851248\u002Fdeepfakes-ai-fake-audio-phone-calls-thieves-trick-companies-stealing-money\" rel=\"nofollow\" target=\"_blank\"\u003Ea chief executive from the United Kingdom wasn‚Äôt so lucky\u003C\u002Fa\u003E.\u003C\u002Fp\u003E"}};b[2]={option:{id:"ef96e045-f7d4-4e7d-b16a-0631bf2393fd",title:e,a:{content:"SURE! ü•ò",id:"6cf46149-0891-41ab-9525-10be2d72bfd8"},b:{content:"NO WAY ‚ùå",id:"99c025c4-2073-45cb-a61a-610bb5585020"},slug:e},image:"gifs\u002Fg4",prompt:{text:"\u003Cp\u003EAn aspiring actor, you land your first big part in the newest installment of a franchise. Upon close inspection of the paperwork, you read that the production company can ‚Äúdigitally resurrect‚Äù both your likeness and your voice if you were to be injured or worse during production. The company claims your character is essential to the plot and they wouldn‚Äôt want to anger anyone if, god forbid, anything happened to you. Time is running out and if you don‚Äôt sign soon they‚Äôll be sure to replace you with someone else. Do you accept the job?\u003C\u002Fp\u003E"},response:{text:"\u003Cp\u003EWe have all heard about the frightening and potentially catastrophic effects deepfakes can have on our media-based society, but it‚Äôs not all bad news. The entertainment industry has been exploring their creative power. CGI experts have already convincingly recreated deceased actors such as \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=fYWv1oD3dv8&amp;ab_channel=dionicus\" rel=\"nofollow\" target=\"_blank\"\u003EAudrey Hepburn‚Äôs 2013 appearance in a Galaxy Chocolate commercial\u003C\u002Fa\u003E and \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.hollywoodreporter.com\u002Fbehind-screen\u002Fhow-furious-7-brought-late-845763\" rel=\"nofollow\" target=\"_blank\"\u003EPaul Walker‚Äôs final moments in Furious 7\u003C\u002Fa\u003E. Artificial intelligence and deepfake technology will only streamline this re-creation process while also rendering faces at an even higher degree of realism. Artists and technologists have begun utilizing the latest technology available to compare the differences between CGI and deepfakes, as seen in this recreation of \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=byKy9kGnyvo&amp;ab_channel=Shamook\" rel=\"nofollow\" target=\"_blank\"\u003Ea young Carrie Fisher in Star Wars\u003C\u002Fa\u003E.\u003C\u002Fp\u003E"}};b[3]={option:{id:"281d07a1-fe71-44e6-ab53-34fb701319f9",title:f,a:{content:"THE WORLD NEEDS MORE TUPAC üé∂",id:"7e6ad162-91b9-4a7f-be1e-22597ac665a0"},b:{content:"I‚ÄôM SORRY, NO üö´",id:"a2c9bb80-2cb0-4896-8e75-0a24e2fabdfd"},slug:f},image:"gifs\u002Fg5",prompt:{text:"\u003Cp\u003EYou‚Äôre listening to the radio and hear a new song that sounds like Tupac but you sure as hell know that it‚Äôs not. The radio host announces that the song you just heard was a synthesized version of Tupac‚Äôs voice, music and sound. New technology like this is making it easier to imitate people, dead or alive, so you might be hearing new Tupac songs from now on. Do you think it‚Äôs okay this song was made without Tupac‚Äôs permission or involvement?\u003C\u002Fp\u003E"},response:{text:"\u003Cp\u003EThe music industry has attempted to bring a musician‚Äôs physical being and voice, like that of \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Ftheundefeated.com\u002Ffeatures\u002Fthe-strange-legacy-of-tupacs-hologram-after-coachella\u002F\" rel=\"nofollow\" target=\"_blank\"\u003ETupac\u003C\u002Fa\u003E and \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.rollingstone.com\u002Fmusic\u002Fmusic-news\u002Fwhitney-houston-hologram-tour-preview-954242\u002F\" rel=\"nofollow\" target=\"_blank\"\u003EWhitney Houston\u003C\u002Fa\u003E, back to life using holograms. These holograms are designed to perform songs the artists once played, not to write new content. Open AI, an artificial intelligence research laboratory, has explored what the future of music can look like with its latest project called \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fjukebox.openai.com\u002F\" rel=\"nofollow\" target=\"_blank\"\u003EJukebox\u003C\u002Fa\u003E, which generates music in the style of specific artists, like Michael Jackson or Ed Sheeran. Recently, rapper \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fyr.media\u002Ftech\u002Fon-to-the-next-one-jay-z-beefs-with-a-i-are-other-artists-next\u002F\" rel=\"nofollow\" target=\"_blank\"\u003EJay Z attempted to get a Youtube video of him reciting Shakespeare taken down \u003C\u002Fa\u003Efrom the platform since it was a vocal synthesis rendering the audio.\u003C\u002Fp\u003E"}};return {data:[{postData:{baseURL:"\u002Fdouble-take-four-deepfake-scenarios",title:"Doing a Double Take: Four Deepfake Scenarios That Mess With Our Minds",author:a,publishDate:"Dec. 2, 2020",location:"Oakland, CA",description:"Deepfakes use artificial intelligence to manipulate a person‚Äôs voice and image. From movies to music, news to the workplace, how do we draw the line between the real and the fake?",tweetMessage:"with @itsyrmedia",url:"https:\u002F\u002Finteractive.yr.media\u002Fdouble-take-four-deepfake-scenarios",featureImage:"https:\u002F\u002Finteractive.yr.media\u002Fdouble-take-four-deepfake-scenarios\u002Fsocial.jpg",featureImagePath:"images\u002Ftemplate-feature-image",featureImageDescription:"People Protesting BLM",featureImageCaption:"(Photo: Andersen Ross Photography Inc\u002FGetty Images)",wpPostSlug:"north-carolina-vs-vaping-companies",wpPostID:"60986",fbAppID:"73080818131",twitterHandler:"@itsyrmedia",docs:[{name:"Deepfake writing assignment - backend",id:"19ZB-U9LdMPbIFjT9RJ8HBh8fCoQnKzoJCDnus9tK_j0"}],dataPath:"data\u002Fdata.json",POLLSERVER:"https:\u002F\u002Fee51aej7u4.execute-api.us-west-2.amazonaws.com\u002Flatest"},articleData:{intro:{text:"\u003Cp\u003EAs if it weren‚Äôt hard enough to separate truth from lies on the internet, more and more so-called \"\u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fyr.media\u002Fpodcasts\u002Ffake-ish\u002F\" rel=\"nofollow\" target=\"_blank\"\u003Edeepfakes\u003C\u002Fa\u003E\" are surging onto the scene. Fake news is nothing new, but deepfakes have been making recent headlines for their scary ability to spread misinformation that‚Äôs extremely hard to detect.\u003C\u002Fp\u003E\n\u003Cp\u003ESimply put, a deepfake ‚Äî sometimes referred to as artificially synthesized media ‚Äî is a kind of photoshop for videos powered by artificial intelligence to manipulate images, audio and video to create altered content. You may have seen an example of a deepfake two years ago, \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.theverge.com\u002F2019\u002F6\u002F11\u002F18662027\u002Finstagram-facebook-deepfake-nancy-pelosi-mark-zuckerberg\" rel=\"nofollow\" target=\"_blank\"\u003Ewhen a fake video of Mark Zuckerberg made national news\u003C\u002Fa\u003E. Or maybe you saw a video of Jordan Peele \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=cQ54GDm1eL0&amp;feature=emb_title\" rel=\"nofollow\" target=\"_blank\"\u003Eimpersonating former president Barack Obama.\u003C\u002Fa\u003E But these only scratch the surface of how deepfakes can be used. The following four scenarios highlight the various ways deepfakes are having an impact - and not just on politics.\u003C\u002Fp\u003E",image:"gifs\u002Fg1"},scenarios:b,conclusion:{text:"\u003Cp\u003ESo, how can you spot a deepfake to prevent some of these scenarios from happening? Unfortunately, because this technology is rapidly getting better, detecting a deepfake is a bit like playing whack-a-mole ‚Äî as soon as someone finds a telltale sign of a deepfake, someone else will find a way to make deepfakes more convincing. \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Fwww.theverge.com\u002F2019\u002F6\u002F27\u002F18715235\u002Fdeepfake-detection-ai-algorithms-accuracy-will-they-ever-work\" rel=\"nofollow\" target=\"_blank\"\u003EFor example, as soon as one researcher noted that subjects in deepfake videos didn‚Äôt blink or didn‚Äôt blink often, people started creating deepfakes that did so.\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EAs of right now, some ways you can try to detect deepfakes include:\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003ELooking for skin discoloration\u003C\u002Fli\u003E\n\u003Cli\u003EPoor lip synchronization\u003C\u002Fli\u003E\n\u003Cli\u003EMismatched voice\u003C\u002Fli\u003E\n\u003Cli\u003EParts of the face that don't match (i.e. a nose or mouth being too small for the face)\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\n\u003Cp\u003EHowever, here‚Äôs something even more important when you‚Äôre out to spot deep fakes: thinking critically. If you‚Äôre watching a video, ask yourself: ‚ÄúDoes what this person is saying or doing make sense for them? Does this match up with what I know about this person?‚Äù Remember, deepfakes are getting smarter all the time, but so are you.\u003C\u002Fp\u003E"},credits:{list:[{title:"Writer",names:a,slug:"writer"},{title:"Editors",names:"Marjerrie Masicat, Lissa Soep",slug:"editors"},{title:"Producers",names:"Zoe Harwood, Dante Ruberto, Bayani Salgado, Elisabeth Guta, Nimah Gobir, Devin Glover",slug:"producers"},{title:"Designer",names:"Marjerrie Masicat",slug:"designer"},{title:"Developer",names:"Radam√©s Ajna",slug:"developer"},{title:"Images",names:"GIPHY \u002F Tones And I, Marc Rodriguez",slug:"images"}],text:"\u003Cp\u003EYR Media has been investigating artificial intelligence and making stories, apps and learning resources about A.I. through an equity lens. Check out our other content \u003Ca class=\"link green underline underline-hover hover-dark-green\" href=\"https:\u002F\u002Finteractive.yr.media\u002Foutsmarting-ai\u002F\" rel=\"nofollow\" target=\"_blank\"\u003Ehere\u003C\u002Fa\u003E. We are grateful for support in this work from the National Science Foundation. Views expressed here are our own and do not necessarily reflect those of the NSF.\u003C\u002Fp\u003E"}},scenarios:b}],fetch:[],mutations:void 0}}("Zoe Harwood",Array(4),"deepfakes1","deepfakes2","deepfakes3","deepfakes4")));