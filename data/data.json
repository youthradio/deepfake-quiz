{"content":[{"intro":{"text":"<p>As if it weren‚Äôt hard enough to separate truth from lies on the internet, more and more so-called \"<a class=\"link green underline underline-hover hover-dark-green\" href=\"https://yr.media/podcasts/fake-ish/\" rel=\"nofollow\" target=\"_blank\">deepfakes</a>\" are surging onto the scene. Fake news is nothing new, but deepfakes have been making recent headlines for their scary ability to spread misinformation that‚Äôs extremely hard to detect.</p>\n<p>Simply put, a deepfake ‚Äî sometimes referred to as artificially synthesized media ‚Äî is a kind of photoshop for videos powered by artificial intelligence to manipulate images, audio and video to create altered content. You may have seen an example of a deepfake two years ago, <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2019/6/11/18662027/instagram-facebook-deepfake-nancy-pelosi-mark-zuckerberg\" rel=\"nofollow\" target=\"_blank\">when a fake video of Mark Zuckerberg made national news</a>. Or maybe you saw a video of Jordan Peele <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.youtube.com/watch?v=cQ54GDm1eL0&amp;feature=emb_title\" rel=\"nofollow\" target=\"_blank\">impersonating former president Barack Obama.</a> But these only scratch the surface of how deepfakes can be used. The following four scenarios highlight the various ways deepfakes are having an impact - and not just on politics.</p>","image":"gifs/g1"},"scenarios":[{"option":{"id":"dcda55ac-2857-4269-8ac5-17e97c027680","title":"deepfakes1","a":{"content":"‚ú® REAL ‚ú®","id":"c49f9c1c-781e-4c26-8b3f-e6685c1a4b7b"},"b":{"content":"‚ÄºÔ∏è FAKE ‚ÄºÔ∏è","id":"ba6baff3-d450-48b3-9d52-7c919ea6033c"},"slug":"deepfakes1"},"image":"gifs/g2","prompt":{"text":"<p>Your friends send you a text message of a video with a politician talking about an inflammatory topic, but the video seems kind of strange. First off, the title seems like it‚Äôs trying to make you angry. Also, in the video, the politician isn‚Äôt blinking and seems to be stuttering a little. That‚Äôs not normal, is it? But the voice sounds real enough, and this definitely isn‚Äôt an impostor ... so you can‚Äôt quite decide. Is this video real and can you trust the information you‚Äôre getting from it?</p>"},"response":{"text":"<p>In some cases, the mere suspicion that a strange video is a deepfake can be enough to cause turmoil. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.washingtonpost.com/politics/2020/02/13/how-sick-president-suspect-video-helped-sparked-an-attempted-coup-gabon/\" rel=\"nofollow\" target=\"_blank\">This happened in the country of Gabon</a>. When their president fell ill in Saudi Arabia, vague and conflicting government reports about his health led to people spreading conspiracy theories that he was dead and had been replaced by a body double. Eventually, these theories had become so prevalent that when the president finally gave a public speech, many assumed the footage of the speech was a deepfake. Eventually there was even a coup attempt from opposition parties ‚Äî even though, according to deepfake experts, the video appeared to be completely real!</p>"}},{"option":{"id":"0cc7baa0-6d89-46cc-b454-0dfe18ccf2d6","title":"deepfakes2","a":{"content":"TOTALLY NORMAL! üòä","id":"c1055239-6faa-4ac0-a9bc-93d94193fc99"},"b":{"content":"PROBABLY A SCAM ü§î","id":"6ed3a2d3-6578-48f0-8d8e-3d11ab3b1aa3"},"slug":"deepfakes2"},"image":"gifs/g3","prompt":{"text":"<p>You get a phone call from one of your coworkers at a really late hour. You don‚Äôt recognize the number they're calling from (maybe they got a new phone?), but you recognize their voice immediately even though it‚Äôs kind of mangled. They‚Äôre calling to tell you that the company needs you to put $1000 into this coworker‚Äôs bank account for ‚Äúbusiness purposes.‚Äù When you ask for details, they don‚Äôt say anything more, instead asking again for the $1000. Will you put the money in the bank account?</p>"},"response":{"text":"<p>This actually happened to an anonymous employee at an unidentified tech firm earlier this year. This <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2020/7/27/21339898/deepfake-audio-voice-clone-scam-attempt-nisos\" rel=\"nofollow\" target=\"_blank\">employee received a phone call from a hacker and scammer</a> using an audio deepfake to impersonate the company‚Äôs CEO. The voicemail left on the employee‚Äôs phone was asking for ‚Äúimmediate assistance to finalize an urgent business deal‚Äù in a human-like voice that sounded only vaguely like the CEO. Luckily, the anonymous employee immediately found it suspicious and didn‚Äôt give the scammers what they wanted. Though this anonymous employee caught on rather quickly, <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2019/9/5/20851248/deepfakes-ai-fake-audio-phone-calls-thieves-trick-companies-stealing-money\" rel=\"nofollow\" target=\"_blank\">a chief executive from the United Kingdom wasn‚Äôt so lucky</a>.</p>"}},{"option":{"id":"ef96e045-f7d4-4e7d-b16a-0631bf2393fd","title":"deepfakes3","a":{"content":"SURE! ü•ò","id":"6cf46149-0891-41ab-9525-10be2d72bfd8"},"b":{"content":"NO WAY ‚ùå","id":"99c025c4-2073-45cb-a61a-610bb5585020"},"slug":"deepfakes3"},"image":"gifs/g4","prompt":{"text":"<p>An aspiring actor, you land your first big part in the newest installment of a franchise. Upon close inspection of the paperwork, you read that the production company can ‚Äúdigitally resurrect‚Äù both your likeness and your voice if you were to be injured or worse during production. The company claims your character is essential to the plot and they wouldn‚Äôt want to anger anyone if, god forbid, anything happened to you. Time is running out and if you don‚Äôt sign soon they‚Äôll be sure to replace you with someone else. Do you accept the job?</p>"},"response":{"text":"<p>We have all heard about the frightening and potentially catastrophic effects deepfakes can have on our media-based society, but it‚Äôs not all bad news. The entertainment industry has been exploring their creative power. CGI experts have already convincingly recreated deceased actors such as <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.youtube.com/watch?v=fYWv1oD3dv8&amp;ab_channel=dionicus\" rel=\"nofollow\" target=\"_blank\">Audrey Hepburn‚Äôs 2013 appearance in a Galaxy Chocolate commercial</a> and <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.hollywoodreporter.com/behind-screen/how-furious-7-brought-late-845763\" rel=\"nofollow\" target=\"_blank\">Paul Walker‚Äôs final moments in Furious 7</a>. Artificial intelligence and deepfake technology will only streamline this re-creation process while also rendering faces at an even higher degree of realism. Artists and technologists have begun utilizing the latest technology available to compare the differences between CGI and deepfakes, as seen in this recreation of <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.youtube.com/watch?v=byKy9kGnyvo&amp;ab_channel=Shamook\" rel=\"nofollow\" target=\"_blank\">a young Carrie Fisher in Star Wars</a>.</p>"}},{"option":{"id":"281d07a1-fe71-44e6-ab53-34fb701319f9","title":"deepfakes4","a":{"content":"THE WORLD NEEDS MORE TUPAC üé∂","id":"7e6ad162-91b9-4a7f-be1e-22597ac665a0"},"b":{"content":"I‚ÄôM SORRY, NO üö´","id":"a2c9bb80-2cb0-4896-8e75-0a24e2fabdfd"},"slug":"deepfakes4"},"image":"gifs/g5","prompt":{"text":"<p>You‚Äôre listening to the radio and hear a new song that sounds like Tupac but you sure as hell know that it‚Äôs not. The radio host announces that the song you just heard was a synthesized version of Tupac‚Äôs voice, music and sound. New technology like this is making it easier to imitate people, dead or alive, so you might be hearing new Tupac songs from now on. Do you think it‚Äôs okay this song was made without Tupac‚Äôs permission or involvement?</p>"},"response":{"text":"<p>The music industry has attempted to bring a musician‚Äôs physical being and voice, like that of <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://theundefeated.com/features/the-strange-legacy-of-tupacs-hologram-after-coachella/\" rel=\"nofollow\" target=\"_blank\">Tupac</a> and <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.rollingstone.com/music/music-news/whitney-houston-hologram-tour-preview-954242/\" rel=\"nofollow\" target=\"_blank\">Whitney Houston</a>, back to life using holograms. These holograms are designed to perform songs the artists once played, not to write new content. Open AI, an artificial intelligence research laboratory, has explored what the future of music can look like with its latest project called <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://jukebox.openai.com/\" rel=\"nofollow\" target=\"_blank\">Jukebox</a>, which generates music in the style of specific artists, like Michael Jackson or Ed Sheeran. Recently, rapper <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://yr.media/tech/on-to-the-next-one-jay-z-beefs-with-a-i-are-other-artists-next/\" rel=\"nofollow\" target=\"_blank\">Jay Z attempted to get a Youtube video of him reciting Shakespeare taken down </a>from the platform since it was a vocal synthesis rendering the audio.</p>"}}],"conclusion":{"text":"<p>So, how can you spot a deepfake to prevent some of these scenarios from happening? Unfortunately, because this technology is rapidly getting better, detecting a deepfake is a bit like playing whack-a-mole ‚Äî as soon as someone finds a telltale sign of a deepfake, someone else will find a way to make deepfakes more convincing. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2019/6/27/18715235/deepfake-detection-ai-algorithms-accuracy-will-they-ever-work\" rel=\"nofollow\" target=\"_blank\">For example, as soon as one researcher noted that subjects in deepfake videos didn‚Äôt blink or didn‚Äôt blink often, people started creating deepfakes that did so.</a></p>\n<p>As of right now, some ways you can try to detect deepfakes include:</p>\n<ul>\n<li>Looking for skin discoloration</li>\n<li>Poor lip synchronization</li>\n<li>Mismatched voice</li>\n<li>Parts of the face that don't match (i.e. a nose or mouth being too small for the face)</li>\n</ul>\n\n<p>However, here‚Äôs something even more important when you‚Äôre out to spot deep fakes: thinking critically. If you‚Äôre watching a video, ask yourself: ‚ÄúDoes what this person is saying or doing make sense for them? Does this match up with what I know about this person?‚Äù Remember, deepfakes are getting smarter all the time, but so are you.</p>"},"credits":{"list":[{"title":"Writer","names":"Zoe Harwood","slug":"writer"},{"title":"Editors","names":"Marjerrie Masicat, Lissa Soep","slug":"editors"},{"title":"Producers","names":"Zoe Harwood, Dante Ruberto, Bayani Salgado, Elisabeth Guta, Nimah Gobir, Devin Glover","slug":"producers"},{"title":"Designer","names":"Marjerrie Masicat","slug":"designer"},{"title":"Developer","names":"Radam√©s Ajna","slug":"developer"},{"title":"Images","names":"GIPHY / Tones And I, Marc Rodriguez","slug":"images"}],"text":"<p>YR Media has been investigating artificial intelligence and making stories, apps and learning resources about A.I. through an equity lens. Check out our other content <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://interactive.yr.media/outsmarting-ai/\" rel=\"nofollow\" target=\"_blank\">here</a>. We are grateful for support in this work from the National Science Foundation. Views expressed here are our own and do not necessarily reflect those of the NSF.</p>"}}]}