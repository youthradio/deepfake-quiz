{"content":[{"intro":{"text":"<p>As if it wasn’t hard enough to separate truth from lies on the internet, a new synthetic media  dubbed “deepfakes” have popped up to the scenes. Misinformation and fake news is nothing new, but deepfakes have been making headlines for it’s scary ability to spread misinformation even further.</p>\n<p>Simply put, deepfakes — sometimes referred to as artificially synthesized media — is a kind of photoshop for videos powered by artificial intelligence to manipulate images, audio and video to create altered content. You may have seen an example of a deepfake two years ago, <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.facebook.com/will.allen.9400/videos/vb.100000114931553/4805424976137953/?type=2&amp;theater\" rel=\"nofollow\" target=\"_blank\">when a fake video of a drunk Nancy Pelosi made national news</a>. Or maybe you saw a video of Jordan Peele <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.youtube.com/watch?v=cQ54GDm1eL0&amp;feature=emb_title\" rel=\"nofollow\" target=\"_blank\">impersonating former president Barack Obama.</a> But these only scratch the surface of how deepfakes can be used. The following four scenarios highlight the various ways deepfakes can be used - not just for politics.</p>"},"scenarios":[{"option":{"a":{"content":"✨ REAL ✨","id":"dfsdfsdf"},"b":{"content":"‼️ FAKE ‼️","id":"dfsdfsdf"}},"image":"gifs/g2","prompt":{"text":"<p>Your friends send you a text message of a video with a politician talking about an inflammatory topic, but the video seems kind of strange. First off, the title of the video seems like it’s trying to make you angry, but also in the video the politician isn’t blinking and stuttering a little? That’s not normal, is it? But on the other hand, the voice sounds real enough, and this definitely isn’t an impostor... so you can’t quite decide. Is this video real and can you trust the information you’re getting from it?</p>"},"response":{"text":"<p>In some cases, the mere suspicion that a strange video is a deepfake can be enough to cause turmoil. This happened in the country of Gabon. When their president fell in Saudi Arabia, vague and conflicting government reports about his health led to people spreading conspiracy theories that he was dead and had been replaced with a body double. Eventually, these theories had become so prevalent that when the president finally gave a public speech, many assumed the footage of the speech was a deepfake. This ended up leading to a coup attempt from opposition parties - even though, according to deepfake experts, the video appeared to be completely real! <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.washingtonpost.com/politics/2020/02/13/how-sick-president-suspect-video-helped-sparked-an-attempted-coup-gabon/\" rel=\"nofollow\" target=\"_blank\">Article about how merley the SUSPICION that a presidential video was a deepfake led to a coup attempt in Gabon</a></p>"}},{"option":{"a":{"content":"TOTALLY NORMAL! 😊","id":"asdfadf"},"b":{"content":"PROBABLY A SCAM 🤔","id":"asdfasf"}},"image":"gifs/g3","prompt":{"text":"<p>You get a phone call from one of your coworkers at a really late hour. Even though you don’t recognize the number they're calling from (maybe they got a new phone?), you recognize their voice immediately even though it’s kind of mangled up. They’re calling to tell you that the company needs you to put $1000 into his bank account for “business purposes.” When you ask for more details, they don’t say anything more, instead asking you for the $1000 again. Will you put the money in the bank account?</p>"},"response":{"text":"<p>This actually happened to an anonymous employee at a tech firm. This employee received a phone call from a hacker using an audio deepfake to impersonate the company’s CEO of the company. Luckily, the anonymous employee immediately found it suspicious and didn’t give the scammers what they wanted. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2020/7/27/21339898/deepfake-audio-voice-clone-scam-attempt-nisos#:~:text=One%20of%20the%20stranger%20applications,where%20it%20shouldn't%20be\" rel=\"nofollow\" target=\"_blank\">Article about a similar audio deepfake scam </a></p>"}},{"option":{"a":{"content":"SURE! 🥘","id":"asdfadf"},"b":{"content":"NO WAY ❌","id":"asdfasf"}},"image":"gifs/g4","prompt":{"text":"<p>An aspiring actor, you land your first big part in the newest installment of a franchise. Upon a close inspection of the paperwork, you read that the production company can “digitally resurrect” both your likeness and your voice if you were to be injured or worse during production. The company claims your character is essential to the plot and they wouldn’t want to anger anyone if, god forbid, anything happened to you. Time is running out and if you don’t choose soon they’ll be sure to replace you with someone else. Do you accept the job?</p>"},"response":{"text":"<p>Deepfakes in entertainment are actually becoming more and more common - a notable example of this was the appearance of Princess Leia in Rouge One. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://thenextweb.com/podium/2019/06/16/the-ethics-of-deepfakes-arent-always-black-and-white/\" rel=\"nofollow\" target=\"_blank\">Article about a similar scenario involving dead actors in a Disney Franchise (article is about morality of deepfakes in general)</a></p>"}},{"option":{"a":{"content":"THE WORLD NEEDS MORE TUPAC 🎶","id":"asdfadf"},"b":{"content":"I’M SORRY, NO 🚫","id":"asdfasf"}},"image":"gifs/g5","prompt":{"text":"<p>You’re listening to the radio and hear a new song that sounds like Tupac but you sure as hell know that it’s not. The radio host announces that the song you just heard was a synthesized version of Tupac’s voice, music, and sound. New technology like this is making it easier to imitate people, dead or alive, so you might be hearing new Tupac songs from now on. Do you think it’s okay this song was made without Tupac’s permission? <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://openai.com/blog/jukebox/\" rel=\"nofollow\" target=\"_blank\">https://openai.com/blog/jukebox/</a></p>"}}],"conclusion":{"text":"<p>So, how can you spot a deepfake to prevent some of these scenarios from happening? </p>\n<p>Unfortunately, because this technology is rapidly getting better, detecting a deepfake is a bit like playing whack-a-mole — as soon as someone finds a telltale sign of a deepfake, someone else will find a way to make deepfakes more convincing. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2019/6/27/18715235/deepfake-detection-ai-algorithms-accuracy-will-they-ever-work\" rel=\"nofollow\" target=\"_blank\">For example, as soon as one researcher noted that subjects in deepfake videos didn’t blink or didn’t blink often, people started creating deepfakes that did so.</a></p>\n<p>As of right now, some ways you can try and detect deepfakes include:</p>\n<ul>\n<li>Looking for skin discoloration</li>\n<li>Poor lip synching</li>\n<li>Mismatched voice</li>\n<li>Parts of the face that don't match (i.e. a nose or mouth being too small for the face)</li>\n</ul>\n\n<p>However, there is a better way to try and spot deep fakes: thinking critically. If you’re watching a video, think to yourself: “Is what this person is saying or doing make sense for them? Does this match up with what I know about this person?” Remember, deepfakes are getting smarter all the time, but so are you.</p>"}}]}