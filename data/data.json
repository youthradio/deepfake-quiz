{"content":[{"intro":{"text":"<p>As if it wasnâ€™t hard enough to separate truth from lies on the internet, a new synthetic media  dubbed â€œdeepfakesâ€ have popped up to the scenes. Misinformation and fake news is nothing new, but deepfakes have been making headlines for itâ€™s scary ability to spread misinformation even further.</p>\n<p>Simply put, deepfakes â€” sometimes referred to as artificially synthesized media â€” is a kind of photoshop for videos powered by artificial intelligence to manipulate images, audio and video to create altered content. You may have seen an example of a deepfake two years ago, <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.facebook.com/will.allen.9400/videos/vb.100000114931553/4805424976137953/?type=2&amp;theater\" rel=\"nofollow\" target=\"_blank\">when a fake video of a drunk Nancy Pelosi made national news</a>. Or maybe you saw a video of Jordan Peele <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.youtube.com/watch?v=cQ54GDm1eL0&amp;feature=emb_title\" rel=\"nofollow\" target=\"_blank\">impersonating former president Barack Obama.</a> But these only scratch the surface of how deepfakes can be used. The following four scenarios highlight the various ways deepfakes can be used - not just for politics.</p>"},"scenarios":[{"option":{"a":{"content":"âœ¨ REAL âœ¨","id":"dfsdfsdf"},"b":{"content":"â€¼ï¸ FAKE â€¼ï¸","id":"dfsdfsdf"}},"image":"gifs/g2","prompt":{"text":"<p>Your friends send you a text message of a video with a politician talking about an inflammatory topic, but the video seems kind of strange. First off, the title of the video seems like itâ€™s trying to make you angry, but also in the video the politician isnâ€™t blinking and stuttering a little? Thatâ€™s not normal, is it? But on the other hand, the voice sounds real enough, and this definitely isnâ€™t an impostor... so you canâ€™t quite decide. Is this video real and can you trust the information youâ€™re getting from it?</p>"},"response":{"text":"<p>In some cases, the mere suspicion that a strange video is a deepfake can be enough to cause turmoil. This happened in the country of Gabon. When their president fell in Saudi Arabia, vague and conflicting government reports about his health led to people spreading conspiracy theories that he was dead and had been replaced with a body double. Eventually, these theories had become so prevalent that when the president finally gave a public speech, many assumed the footage of the speech was a deepfake. This ended up leading to a coup attempt from opposition parties - even though, according to deepfake experts, the video appeared to be completely real! <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.washingtonpost.com/politics/2020/02/13/how-sick-president-suspect-video-helped-sparked-an-attempted-coup-gabon/\" rel=\"nofollow\" target=\"_blank\">Article about how merley the SUSPICION that a presidential video was a deepfake led to a coup attempt in Gabon</a></p>"}},{"option":{"a":{"content":"TOTALLY NORMAL! ğŸ˜Š","id":"asdfadf"},"b":{"content":"PROBABLY A SCAM ğŸ¤”","id":"asdfasf"}},"image":"gifs/g3","prompt":{"text":"<p>You get a phone call from one of your coworkers at a really late hour. Even though you donâ€™t recognize the number they're calling from (maybe they got a new phone?), you recognize their voice immediately even though itâ€™s kind of mangled up. Theyâ€™re calling to tell you that the company needs you to put $1000 into his bank account for â€œbusiness purposes.â€ When you ask for more details, they donâ€™t say anything more, instead asking you for the $1000 again. Will you put the money in the bank account?</p>"},"response":{"text":"<p>This actually happened to an anonymous employee at a tech firm. This employee received a phone call from a hacker using an audio deepfake to impersonate the companyâ€™s CEO of the company. Luckily, the anonymous employee immediately found it suspicious and didnâ€™t give the scammers what they wanted. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2020/7/27/21339898/deepfake-audio-voice-clone-scam-attempt-nisos#:~:text=One%20of%20the%20stranger%20applications,where%20it%20shouldn't%20be\" rel=\"nofollow\" target=\"_blank\">Article about a similar audio deepfake scam </a></p>"}},{"option":{"a":{"content":"SURE! ğŸ¥˜","id":"asdfadf"},"b":{"content":"NO WAY âŒ","id":"asdfasf"}},"image":"gifs/g4","prompt":{"text":"<p>An aspiring actor, you land your first big part in the newest installment of a franchise. Upon a close inspection of the paperwork, you read that the production company can â€œdigitally resurrectâ€ both your likeness and your voice if you were to be injured or worse during production. The company claims your character is essential to the plot and they wouldnâ€™t want to anger anyone if, god forbid, anything happened to you. Time is running out and if you donâ€™t choose soon theyâ€™ll be sure to replace you with someone else. Do you accept the job?</p>"},"response":{"text":"<p>Deepfakes in entertainment are actually becoming more and more common - a notable example of this was the appearance of Princess Leia in Rouge One. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://thenextweb.com/podium/2019/06/16/the-ethics-of-deepfakes-arent-always-black-and-white/\" rel=\"nofollow\" target=\"_blank\">Article about a similar scenario involving dead actors in a Disney Franchise (article is about morality of deepfakes in general)</a></p>"}},{"option":{"a":{"content":"THE WORLD NEEDS MORE TUPAC ğŸ¶","id":"asdfadf"},"b":{"content":"Iâ€™M SORRY, NO ğŸš«","id":"asdfasf"}},"image":"gifs/g5","prompt":{"text":"<p>Youâ€™re listening to the radio and hear a new song that sounds like Tupac but you sure as hell know that itâ€™s not. The radio host announces that the song you just heard was a synthesized version of Tupacâ€™s voice, music, and sound. New technology like this is making it easier to imitate people, dead or alive, so you might be hearing new Tupac songs from now on. Do you think itâ€™s okay this song was made without Tupacâ€™s permission? <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://openai.com/blog/jukebox/\" rel=\"nofollow\" target=\"_blank\">https://openai.com/blog/jukebox/</a></p>"}}],"conclusion":{"text":"<p>So, how can you spot a deepfake to prevent some of these scenarios from happening? </p>\n<p>Unfortunately, because this technology is rapidly getting better, detecting a deepfake is a bit like playing whack-a-mole â€” as soon as someone finds a telltale sign of a deepfake, someone else will find a way to make deepfakes more convincing. <a class=\"link green underline underline-hover hover-dark-green\" href=\"https://www.theverge.com/2019/6/27/18715235/deepfake-detection-ai-algorithms-accuracy-will-they-ever-work\" rel=\"nofollow\" target=\"_blank\">For example, as soon as one researcher noted that subjects in deepfake videos didnâ€™t blink or didnâ€™t blink often, people started creating deepfakes that did so.</a></p>\n<p>As of right now, some ways you can try and detect deepfakes include:</p>\n<ul>\n<li>Looking for skin discoloration</li>\n<li>Poor lip synching</li>\n<li>Mismatched voice</li>\n<li>Parts of the face that don't match (i.e. a nose or mouth being too small for the face)</li>\n</ul>\n\n<p>However, there is a better way to try and spot deep fakes: thinking critically. If youâ€™re watching a video, think to yourself: â€œIs what this person is saying or doing make sense for them? Does this match up with what I know about this person?â€ Remember, deepfakes are getting smarter all the time, but so are you.</p>"}}]}